{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim","metadata":{"_uuid":"44ba06de-0d19-4082-b5a4-1fd6526ba5d9","_cell_guid":"d30d6430-7705-4e18-8f99-af41f1add4e2","collapsed":false,"id":"MO7mv382VBHV","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/news-clickbait-dataset/train1.csv')","metadata":{"_uuid":"feac7746-3954-4b7b-9114-b5f57693362a","_cell_guid":"b23ee9d0-c265-4d4e-9c8d-071e3ec3540c","collapsed":false,"id":"nwjxU6fTg4kx","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dic={}\nfor s in data['headline'][:3200]:\n  separated_words=s.split()\n  separated_words.append('.')\n  for w1 ,w2 in zip(separated_words,separated_words[1:]):\n    bigram=(w1,w2)\n    dic[bigram]=dic.get(bigram,0)+1","metadata":{"_uuid":"050ac60f-5d3f-45bf-b84a-186d73b0a703","_cell_guid":"7b2e0178-106e-4d8f-809e-e0242bff7f14","collapsed":false,"id":"YhQgqnXMuwPS","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = set()\nfor key in dic.keys():\n    words.update(key)\n\nwords=list(words)\nwords=sorted(words)\nend_token=words.pop(words.index('.'))\nwords.insert(0,'.')\nstoi = {word: index for index, word in enumerate(words)}","metadata":{"_uuid":"6b383102-89bc-4026-b5da-d63e9ce133c3","_cell_guid":"9d961300-1e53-4ebf-bdc1-122fbbab4033","collapsed":false,"id":"uGWRo4TmToR3","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xs,ys=[],[]\ndic={}\nfor s in data['headline'][:3200]:\n  separated_words=s.split()\n  separated_words.append('.')\n  for w1 ,w2 in zip(separated_words,separated_words[1:]):\n    ix1=stoi[w1]\n    ix2=stoi[w2]\n    xs.append(ix1)\n    ys.append(ix2)\nxs=torch.tensor(xs)\nys=torch.tensor(ys)","metadata":{"_uuid":"b1a90311-2627-4720-898a-3ee8b17b01ac","_cell_guid":"bfa665eb-798c-4d04-b124-67b95d6b7446","collapsed":false,"id":"jJEAKghYUGR_","outputId":"66c10a77-f8bd-433f-98aa-09101d74e904","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(xs)\nprint(ys)","metadata":{"_uuid":"b650592b-8b49-40d9-b3da-ac09a59ef525","_cell_guid":"67873674-0e0c-4617-99b1-13f0157a848e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"W = torch.randn((len(words),len(words)),requires_grad=True)","metadata":{"_uuid":"b08e1128-fb16-403b-ba94-e568955b9398","_cell_guid":"3370f60e-2a1f-4e9f-b550-51786058d5ce","collapsed":false,"id":"tdXtKMbvbj1z","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch=[]\nbatch_size=32\nbatch_ans=[]\nnumber_of_batches=xs.numel()/batch_size\nfor i in range (int(number_of_batches)):\n    batch.append(xs[batch_size*i:batch_size*(i+1)][:])\n    batch_ans.append(ys[batch_size*i:batch_size*(i+1)][:])\n    #if i==int(number_of_batches)-1:\n                #  epoch.append(xs[batch_size*(i+1):xs.shape[0]])\n                #  epoch_ans.append(ys[batch_size*(i+1):ys.shape[0]])","metadata":{"_uuid":"884895b8-699e-4f02-ab88-cd3b0d0c08a8","_cell_guid":"580015b2-e4dc-46ea-a590-454c0562a646","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in range (15):\n    print(k)\n    batch_enc=[]\n    for i in range(len(batch)):\n        W.grad=None\n        #Forward Propagation\n        batch_enc.append(F.one_hot(batch[i],num_classes=len(words)).float().requires_grad_(True))\n    \n    \n        logits=(batch_enc[i] @ W)\n        counts=logits.exp()\n        prob=counts/counts.sum(1,keepdims=True)\n        loss=-prob[torch.arange(32),batch_ans[i]].log().mean()+0.01*(W**2).mean()\n     #Backward Propagation\n        loss.backward() \n        print(loss.item())\n    \n    #Updation of weights\n        W.data += -1 * W.grad\nprint(loss.item())","metadata":{"_uuid":"bfadea70-c3fb-4c10-88d6-2de98c9f2730","_cell_guid":"236a5999-d57e-4ef5-81c6-c760cc0ec0a7","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n  \n  out = []\n  ix = 0\n  for k in range(5):\n    xenc = F.one_hot(torch.tensor([ix]), num_classes=len(words)).float()\n    logits = xenc @ W \n    counts = logits.exp() \n    p = counts / counts.sum(1, keepdims=True) \n    \n    ix = torch.multinomial(p, num_samples=1, replacement=True).item()\n    out.append(words[ix])\n    \n    out.append(' ')\n   \n  print(''.join(out))","metadata":{"_uuid":"5bdd7929-29ef-4aea-896f-d17ca7213a25","_cell_guid":"5b5a4abb-04d2-42c3-9c63-5523d462477b","collapsed":false,"id":"JtrLAKDHyDb7","outputId":"2e25acc8-1cfe-43f2-b938-7fb514f07208","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(W, 'model_weights.pth')","metadata":{"_uuid":"ebe64dbe-22be-45c4-be3a-b147502c7600","_cell_guid":"ca8d8a87-7b12-430f-ae46-af0731813ab1","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}